
@book{sadalage_nosql_2013,
	address = {Upper Saddle River, NJ},
	title = {{NoSQL} distilled: a brief guide to the emerging world of polyglot persistence},
	isbn = {978-0-321-82662-6},
	shorttitle = {{NoSQL} distilled},
	publisher = {Addison-Wesley},
	author = {Sadalage, Pramod J. and Fowler, Martin},
	year = {2013},
	keywords = {Databases, Information storage and retrieval systems, Non-relational databases, Technological innovations},
	file = {Pramod J. Sadalage, Martin Fowler - NoSQL Distilled_ A Brief Guide to the Emerging World of Polyglot Persistence-Addison-Wesley Professional (2012).epub:/home/claudia/Zotero/storage/PARKG4XM/Pramod J. Sadalage, Martin Fowler - NoSQL Distilled_ A Brief Guide to the Emerging World of Polyglot Persistence-Addison-Wesley Professional (2012).epub:application/epub+zip;Pramod J. Sadalage, Martin Fowler - NoSQL Distilled_ A Brief Guide to the Emerging World of Polyglot Persistence-Addison-Wesley Professional (2012).pdf:/home/claudia/Zotero/storage/N5533K9W/Pramod J. Sadalage, Martin Fowler - NoSQL Distilled_ A Brief Guide to the Emerging World of Polyglot Persistence-Addison-Wesley Professional (2012).pdf:application/pdf},
}

@article{ma_self-driving_nodate,
	title = {Self-{Driving} {Database}  {Management} {Systems}: {Forecasting}, {Modeling}, and {Planning}},
	language = {en},
	author = {Ma, Lin},
	pages = {125},
	file = {Ma - Self-Driving Database  Management Systems Forecas.pdf:/home/claudia/Zotero/storage/2BIVSLPD/Ma - Self-Driving Database  Management Systems Forecas.pdf:application/pdf},
}

@article{mozaffari_new_2019,
	title = {A {New} {Solution} for {Workload} {Change} {Detection} in {Self}-{Tuning} {NoSQL} {Database}},
	volume = {49},
	issn = {2008-7799},
	url = {https://tjee.tabrizu.ac.ir/article_9590.html},
	abstract = {Database management systems are the main part of information system that the size and complexity of these systems significantly have been increased in recent years. With the growing and being more complicated database management systems, database Administrators face more problems and challenges, so management of these systems is Time-consuming and costly. More over the main part of the total cost of ownership includes the cost of expert database administrator (DBA) who can manage these large and complicated systems. Autonomic databases by providing self-management functionality are caused to reduce the total cost of ownership for a database system. The self-management decisions as the automated schema database tuning depend on the database workload. One of the important issues in realizing the database automated tuning is workload monitoring and analysis for changes detection and schema re-tuning with this changes. In this paper is presented the feedback control loop for continuous monitoring and light-weight analysis of workload in NoSQL column-oriented database. This loop describes a design pattern for self-tuning feature and uses for workload change detection which require automated schema database re-tuning. The experimental results exhibit the effectiveness of the proposed solution for workload change detection.},
	number = {3},
	urldate = {2022-01-06},
	journal = {TABRIZ JOURNAL OF ELECTRICAL ENGINEERING},
	author = {Mozaffari, M. and Nazemi, E. and Eftekhari Moghadam, A. M.},
	month = dec,
	year = {2019},
	note = {Publisher: Faculty of Electrical \& Computer Engineering},
	pages = {1317--1331},
	file = {Full Text PDF:/home/claudia/Zotero/storage/XVSHBKES/Mozaffari et al. - 2019 - A New Solution for Workload Change Detection in Se.pdf:application/pdf;Snapshot:/home/claudia/Zotero/storage/C2DFXXS7/article_9590.html:text/html},
}

@inproceedings{brahim_model_2019,
	address = {Vienna, Austria},
	title = {Model {Driven} {Extraction} of {NoSQL} {Databases} {Schema}: {Case} of {MongoDB}:},
	isbn = {978-989-758-382-7},
	shorttitle = {Model {Driven} {Extraction} of {NoSQL} {Databases} {Schema}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0008176201450154},
	doi = {10.5220/0008176201450154},
	language = {en},
	urldate = {2022-01-06},
	booktitle = {Proceedings of the 11th {International} {Joint} {Conference} on {Knowledge} {Discovery}, {Knowledge} {Engineering} and {Knowledge} {Management}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Brahim, Amal and Ferhat, Rabah and Zurfluh, Gilles},
	year = {2019},
	pages = {145--154},
	file = {Brahim et al. - 2019 - Model Driven Extraction of NoSQL Databases Schema.pdf:/home/claudia/Zotero/storage/N6QJISMR/Brahim et al. - 2019 - Model Driven Extraction of NoSQL Databases Schema.pdf:application/pdf},
}

@inproceedings{abdelhadi_applying_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Applying a {Model}-{Driven} {Approach} for {UML}/{OCL} {Constraints}: {Application} to {NoSQL} {Databases}},
	isbn = {978-3-030-33246-4},
	shorttitle = {Applying a {Model}-{Driven} {Approach} for {UML}/{OCL} {Constraints}},
	doi = {10.1007/978-3-030-33246-4_40},
	abstract = {Big Data have received a great deal of attention in recent years. Not only the amount of data is on a completely different level than before, but also we have different type of data including factors such as format, structure, and sources. This has definitely changed the tools we need to handle Big Data, giving rise to NoSQL systems. While NoSQL systems have proven their efficiency to handle Big Data, it’s still an unsolved problem how the automatic storage of Big Data in NoSQL systems could be done. This paper proposes an automatic approach for implementing UML conceptual models in NoSQL systems, including the mapping of the associated OCL constraints to the code required for checking them. In order to demonstrate the practical applicability of our work, we have realized it in a tool supporting four fundamental OCL expressions: Iterate-based expressions, OCL predefined operations, If expression and Let expression.},
	language = {en},
	booktitle = {On the {Move} to {Meaningful} {Internet} {Systems}: {OTM} 2019 {Conferences}},
	publisher = {Springer International Publishing},
	author = {Abdelhadi, Fatma and Ait Brahim, Amal and Zurfluh, Gilles},
	editor = {Panetto, Hervé and Debruyne, Christophe and Hepp, Martin and Lewis, Dave and Ardagna, Claudio Agostino and Meersman, Robert},
	year = {2019},
	keywords = {Big data, MDA, NoSQL, OCL, QVT, UML},
	pages = {646--660},
	file = {Abdelhadi et al_2019_Applying a Model-Driven Approach for UML-OCL Constraints.pdf:/home/claudia/Zotero/storage/EZRPJ8ID/Abdelhadi et al_2019_Applying a Model-Driven Approach for UML-OCL Constraints.pdf:application/pdf},
}

@book{panetto_move_2019,
	address = {Cham, Switzerland},
	title = {On the move to meaningful internet systems: {OTM} 2019 {Conferences}: {Confederated} {International} {Conferences}: {CoopIS}, {ODBASE}, {C}\&{TC} 2019, {Rhodes}, {Greece}, {October} 21-25, 2019: proceedings},
	isbn = {978-3-030-33246-4 978-3-030-33245-7},
	shorttitle = {On the move to meaningful internet systems},
	language = {eng},
	publisher = {Springer},
	editor = {Panetto, Hervé and Debruyne, Christophe and Hepp, Martin and Lewis, Dave and Ardagna, Claudio Agostino and Meersman, Robert},
	year = {2019},
	note = {Meeting Name: CoopIS},
	file = {on-the-move.pdf:/home/claudia/Zotero/storage/PXKV5DWE/on-the-move.pdf:application/pdf;Table of Contents PDF:/home/claudia/Zotero/storage/QTLUAB7G/Panetto et al. - 2019 - On the move to meaningful internet systems OTM 20.pdf:application/pdf},
}

@article{moniruzzaman_nosql_2013,
	title = {{NoSQL} {Database}: {New} {Era} of {Databases} for {Big} data {Analytics} - {Classification}, {Characteristics} and {Comparison}},
	shorttitle = {{NoSQL} {Database}},
	url = {http://arxiv.org/abs/1307.0191},
	abstract = {Digital world is growing very fast and become more complex in the volume (terabyte to petabyte), variety (structured and un-structured and hybrid), velocity (high speed in growth) in nature. This refers to as Big Data that is a global phenomenon. This is typically considered to be a data collection that has grown so large it can not be effectively managed or exploited using conventional data management tools: e.g., classic relational database management systems (RDBMS) or conventional search engines. To handle this problem, traditional RDBMS are complemented by specifically designed a rich set of alternative DBMS; such as - NoSQL, NewSQL and Search-based systems. This paper motivation is to provide - classification, characteristics and evaluation of NoSQL databases in Big Data Analytics. This report is intended to help users, especially to the organizations to obtain an independent understanding of the strengths and weaknesses of various NoSQL database approaches to supporting applications that process huge volumes of data.},
	urldate = {2022-01-06},
	journal = {arXiv:1307.0191 [cs]},
	author = {Moniruzzaman, A. B. M. and Hossain, Syed Akhter},
	month = jun,
	year = {2013},
	note = {arXiv: 1307.0191},
	keywords = {Computer Science - Databases},
	file = {arXiv Fulltext PDF:/home/claudia/Zotero/storage/NQZRG52W/Moniruzzaman und Hossain - 2013 - NoSQL Database New Era of Databases for Big data .pdf:application/pdf;arXiv.org Snapshot:/home/claudia/Zotero/storage/7PTHRJ3H/1307.html:text/html},
}

@inproceedings{abdelhedi_logical_2017,
	address = {Porto, Portugal},
	title = {Logical {Unified} {Modeling} {For} {NoSQL} {DataBases}},
	url = {https://hal.archives-ouvertes.fr/hal-01782574},
	abstract = {NoSQL data stores are becoming widely used to handle Big Data; these systems operate on schema-less data model enabling users to incorporate new data into their applications without using a predefined schema. But, there is still a need for a conceptual model to define how data will be structured in the database. In this paper, we show how to store Big Data described by conceptual model within NoSQL systems. For this, we use the Model Driven Architecture (MDA) that provides a framework for models automatic transformation. Starting from a conceptual model describing a set of complex objects, we propose transformation rules formalized with QVT to generate NoSQL physical models. To ensure efficient automatic transformation and to limit the impacts related to technical aspects of NoSQL systems, we propose a generic logical model that is compatible with the three types of NoSQL systems (column, document and graph). We provide experiments of our approach using a case study related to the hea lth care field. The results of our experiments show that the proposed logical model can be effectively transformed into different NoSQL physical models independently of their specific details.},
	urldate = {2022-01-06},
	booktitle = {19th {International} {Conference} on {Enterprise} {Information} {Systems} ({ICEIS} 2017)},
	author = {Abdelhedi, Fatma and Ait Brahim, Amal and Atigui, Faten and Zurfluh, Gilles},
	month = apr,
	year = {2017},
	keywords = {Big data, MDA, NoSQL, QVT, UML conceptual model},
	pages = {pp. 249--256},
	file = {HAL PDF Full Text:/home/claudia/Zotero/storage/JUKIMAF6/Abdelhedi et al. - 2017 - Logical Unified Modeling For NoSQL DataBases.pdf:application/pdf},
}

@article{pavlo_self-driving_nodate,
	title = {Self-{Driving} {Database} {Management} {Systems}},
	abstract = {In the last two decades, both researchers and vendors have built advisory tools to assist database administrators (DBAs) in various aspects of system tuning and physical design. Most of this previous work, however, is incomplete because they still require humans to make the ﬁnal decisions about any changes to the database and are reactionary measures that ﬁx problems after they occur.},
	language = {en},
	journal = {CIDR},
	author = {Pavlo, Andrew and Angulo, Gustavo and Arulraj, Joy and Lin, Haibin and Lin, Jiexi and Ma, Lin and Menon, Prashanth and Mowry, Todd C and Perron, Matthew and Quah, Ian and Santurkar, Siddharth and Tomasic, Anthony and Toor, Skye and Aken, Dana Van and Wang, Ziqi and Wu, Yingjun and Xian, Ran and Zhang, Tieying},
	pages = {6},
	file = {Pavlo et al. - Self-Driving Database Management Systems.pdf:/home/claudia/Zotero/storage/DKIBZ6CE/Pavlo et al. - Self-Driving Database Management Systems.pdf:application/pdf},
}

@inproceedings{holze_towards_2007,
	address = {Lisbon, Portugal},
	title = {Towards workload shift detection and prediction for autonomic databases},
	isbn = {978-1-59593-832-9},
	url = {http://portal.acm.org/citation.cfm?doid=1316874.1316892},
	doi = {10.1145/1316874.1316892},
	abstract = {Due to the complexity of industry-scale database systems, the total cost of ownership for these systems is no longer dominated by hardware and software, but by administration expenses. Autonomic databases intend to reduce these costs by providing self-management features. Existing approaches towards this goal are supportive advisors for the database administrator and feedback control loops for online monitoring, analysis and re-conﬁguration. But while advisors are too resource-consuming for continuous operation, feedback control loops suﬀer from overreaction, oscillation and interference.},
	language = {en},
	urldate = {2022-01-15},
	booktitle = {Proceedings of the {ACM} first {Ph}.{D}. workshop in {CIKM} on   - {PIKM} '07},
	publisher = {ACM Press},
	author = {Holze, Marc and Ritter, Norbert},
	year = {2007},
	pages = {109},
	file = {Holze und Ritter - 2007 - Towards workload shift detection and prediction fo.pdf:/home/claudia/Zotero/storage/J2YFWXY9/Holze und Ritter - 2007 - Towards workload shift detection and prediction fo.pdf:application/pdf},
}

@incollection{atzeni_autonomic_2008,
	address = {Berlin, Heidelberg},
	title = {Autonomic {Databases}: {Detection} of {Workload} {Shifts} with n-{Gram}-{Models}},
	volume = {5207},
	isbn = {978-3-540-85712-9 978-3-540-85713-6},
	shorttitle = {Autonomic {Databases}},
	url = {http://link.springer.com/10.1007/978-3-540-85713-6_10},
	abstract = {Autonomic databases are intended to reduce the total cost of ownership for a database system by providing self-management functionality. The self-management decisions heavily depend on the database workload, as the workload inﬂuences both the physical design and the DBMS conﬁguration. In particular, a database reconﬁguration is required whenever there is a signiﬁcant change, i.e. shift, in the workload.},
	language = {en},
	urldate = {2022-01-15},
	booktitle = {Advances in {Databases} and {Information} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Holze, Marc and Ritter, Norbert},
	editor = {Atzeni, Paolo and Caplinskas, Albertas and Jaakkola, Hannu},
	year = {2008},
	doi = {10.1007/978-3-540-85713-6_10},
	note = {ISSN: 0302-9743, 1611-3349
Series Title: Lecture Notes in Computer Science},
	pages = {127--142},
	file = {Holze und Ritter - 2008 - Autonomic Databases Detection of Workload Shifts .pdf:/home/claudia/Zotero/storage/INLG8DML/Holze und Ritter - 2008 - Autonomic Databases Detection of Workload Shifts .pdf:application/pdf},
}

@article{mozaffari_feedback_2020,
	title = {Feedback control loop design for workload change detection in self-tuning {NoSQL} wide column stores},
	volume = {142},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417419306918},
	doi = {10.1016/j.eswa.2019.112973},
	abstract = {Database management systems are the main part of information systems that the size and complexity of these systems are increased in recent years. Due to the growing complexity of DBMSs, database administrators (DBAs) face increasingly more problems and challenges, and so managing these systems are difficult and laborious. More over the main part of the total cost of ownership includes the cost of expert database administrator who can manage these large and complicated systems. Autonomic database, by providing self-management functionality, leads to a reduction in the total cost of ownership for the database system. Self-management decisions such as automated schema database tuning are dependent on the database workload. Therefore, one of the important issues in realizing the database automated tuning is workload monitoring and analysis for changes detection and schema re-tuning with this changes. In this paper, a feedback control loop is designed for continuous monitoring and light-weight workload analysis in NoSQL wide column stores. This loop describes a design pattern for the self-tuning feature and it is used to detect workload changes that are necessary for the automated schema database re-tuning. Our concept is based on workload model construction using reconfigurable colored petri-net model. The results of the experiments show the effectiveness of the proposed approach in discovering significant workload changes.},
	language = {en},
	urldate = {2022-05-26},
	journal = {Expert Systems with Applications},
	author = {Mozaffari, Maryam and Nazemi, Eslam and Eftekhari-Moghadam, Amir Masoud},
	month = mar,
	year = {2020},
	keywords = {Autonomic database, Feedback control loop, NoSQL wide column store, Workload change detection, workload monitoring and analysis},
	pages = {112973},
	file = {Mozaffari et al. - 2020 - Feedback control loop design for workload change d.pdf:/home/claudia/Zotero/storage/4CUN8AA6/Mozaffari et al. - 2020 - Feedback control loop design for workload change d.pdf:application/pdf;ScienceDirect Snapshot:/home/claudia/Zotero/storage/3UZMSLIL/S0957417419306918.html:text/html},
}

@inproceedings{agrawal_database_2005,
	address = {New York, NY, USA},
	series = {{SIGMOD} '05},
	title = {Database tuning advisor for microsoft {SQL} server 2005: demo},
	isbn = {978-1-59593-060-6},
	shorttitle = {Database tuning advisor for microsoft {SQL} server 2005},
	url = {https://doi.org/10.1145/1066157.1066292},
	doi = {10.1145/1066157.1066292},
	abstract = {Database Tuning Advisor (DTA) is a physical database design tool that is part of Microsoft's SQL Server 2005 relational database management system. Previously known as "Index Tuning Wizard" in SQL Server 7.0 and SQL Server 2000, DTA adds new functionality that is not available in other contemporary physical design tuning tools. Novel aspects of DTA that will be demonstrated include: (a) Ability to take into account both performance and manageability requirements of DBAs (b) Fully integrated recommendations for indexes, materialized views and horizontal partitioning (c) Transparently leverage a test server to offload tuning load from production server and (d) Easy programmability and scriptability.},
	urldate = {2022-05-27},
	booktitle = {Proceedings of the 2005 {ACM} {SIGMOD} international conference on {Management} of data},
	publisher = {Association for Computing Machinery},
	author = {Agrawal, Sanjay and Chaudhuri, Surajit and Kollar, Lubor and Marathe, Arun and Narasayya, Vivek and Syamala, Manoj},
	month = jun,
	year = {2005},
	pages = {930--932},
	file = {Agrawal et al. - 2005 - Database tuning advisor for microsoft SQL server 2.pdf:/home/claudia/Zotero/storage/UXT7PXXA/Agrawal et al. - 2005 - Database tuning advisor for microsoft SQL server 2.pdf:application/pdf},
}

@incollection{dageville_-_2004,
	address = {St Louis},
	title = {- {Automatic} {SQL} {Tuning} in {Oracle} 10g},
	isbn = {978-0-12-088469-8},
	url = {https://www.sciencedirect.com/science/article/pii/B9780120884698500966},
	abstract = {This chapter presents the new Automatic SQL Tuning feature of Oracle 10g. SQL tuning is a very critical aspect of database performance tuning. It is an inherently complex activity requiring a high level of expertise in several domains: query optimization, to improve the execution plan selected by the query optimizer; access design, to identify missing access structures; and SQL design, to restructure and simplify the text of a badly written SQL statement. Furthermore, the SQL tuning is a time consuming task due to the large volume and evolving nature of the SQL workload and its underlying data. The new Automatic SQL Tuning is implemented as a core enhancement of the Oracle query optimizer and offers a comprehensive solution to the SQL tuning challenges. Automatic SQL Tuning introduces the concept of SQL profiling to transparently improve execution plans. It also generates SQL tuning recommendations by performing cost-based access path and SQL structure “what-if” analyses. The Automatic SQL Tuning is an integral part of the Oracle's framework for self-managing databases.},
	language = {en},
	urldate = {2022-05-27},
	booktitle = {Proceedings 2004 {VLDB} {Conference}},
	publisher = {Morgan Kaufmann},
	author = {Dageville, Benoit and Das, Dinesh and Dias, Karl and Yagoub, Khaled and Zait, Mohamed and Ziauddin, Mohamed},
	editor = {Nascimento, Mario A. and Özsu, M. Tamer and Kossmann, Donald and Miller, Renée J. and Blakeley, José A. and Schiefer, Berni},
	month = jan,
	year = {2004},
	doi = {10.1016/B978-012088469-8.50096-6},
	pages = {1098--1109},
	file = {ScienceDirect Snapshot:/home/claudia/Zotero/storage/V6AZVICM/B9780120884698500966.html:text/html},
}

@inproceedings{papadomanolakis_autopart_2004,
	title = {{AutoPart}: automating schema design for large scientific databases using data partitioning},
	shorttitle = {{AutoPart}},
	doi = {10.1109/SSDM.2004.1311234},
	abstract = {Database applications that use multi-terabyte datasets are becoming increasingly important for scientific fields such as astronomy and biology. Scientific databases are particularly suited for the application of automated physical design techniques, because of their data volume and the complexity of the scientific workloads. Current automated physical design tools focus on the selection of indexes and materialized views. In large-scale scientific databases, however the data volume and the continuous insertion of new data allows for only limited indexes and materialized views. By contrast, data partitioning does not replicate data, thereby reducing space requirements and minimizing update overhead. In this paper we present AutoPart, an algorithm that automatically partitions database tables to optimize sequential access assuming prior knowledge of a representative workload. The resulting schema is indexed using a fraction of the space required for indexing the original schema. To evaluate AutoPart we built an automated schema design tool that interfaces to commercial database systems. We experiment with AutoPart in the context of the Sloan Digital Sky Survey database, a real-world astronomical database, running on SQL Server 2000. Our experiments demonstrate the benefits of partitioning for large-scale systems: partitioning alone improves query execution performance by a factor of two on average. Combined with indexes, the new schema also outperforms the indexed original schema by 20\% (for queries) and a factor of five (for updates), while using only half the original index space.},
	booktitle = {Proceedings. 16th {International} {Conference} on {Scientific} and {Statistical} {Database} {Management}, 2004.},
	author = {Papadomanolakis, S. and Ailamaki, A.},
	month = jun,
	year = {2004},
	note = {ISSN: 1099-3371},
	keywords = {Astronomy, Database systems, Indexes, Indexing, Large-scale systems, Partitioning algorithms, Query processing, Spatial databases, Stress, Telescopes},
	pages = {383--392},
	file = {autopart-automating-schema-design-for-large-scientific-databases.pdf:/home/claudia/Zotero/storage/WI58KFWX/autopart-automating-schema-design-for-large-scientific-databases.pdf:application/pdf;Eingereichte Version:/home/claudia/Zotero/storage/97865IMC/Papadomanolakis und Ailamaki - 2004 - AutoPart automating schema design for large scien.pdf:application/pdf;IEEE Xplore Abstract Record:/home/claudia/Zotero/storage/NXZN362S/1311234.html:text/html},
}

@inproceedings{bruno_online_2007,
	title = {An {Online} {Approach} to {Physical} {Design} {Tuning}},
	doi = {10.1109/ICDE.2007.367928},
	abstract = {There has been considerable work on automated physical design tuning for database systems. Existing solutions require offline invocations of the tuning tool and depend on DBAs identifying representative workloads manually. In this work, we propose an alternative approach to the physical design problem. Specifically we design algorithms that are always-on and continuously modify the current physical design reacting to changes in the query workload. Our techniques have low overhead and take into account storage constraints, update statements, and the cost to create temporary physical structures.},
	booktitle = {2007 {IEEE} 23rd {International} {Conference} on {Data} {Engineering}},
	author = {Bruno, Nicolas and Chaudhuri, Surajit},
	month = apr,
	year = {2007},
	note = {ISSN: 2375-026X},
	keywords = {Database systems, Query processing, Spatial databases, Algorithm design and analysis, Computer bugs, Computerized monitoring, Costs, Feeds, Tuning},
	pages = {826--835},
	file = {Bruno und Chaudhuri - 2007 - An Online Approach to Physical Design Tuning.pdf:/home/claudia/Zotero/storage/F8QZYXMQ/Bruno und Chaudhuri - 2007 - An Online Approach to Physical Design Tuning.pdf:application/pdf;IEEE Xplore Abstract Record:/home/claudia/Zotero/storage/PBDD5TZS/4221731.html:text/html},
}

@inproceedings{rasin_automatic_2013,
	address = {New York, NY, USA},
	series = {{EDBT} '13},
	title = {An automatic physical design tool for clustered column-stores},
	isbn = {978-1-4503-1597-5},
	url = {https://doi.org/10.1145/2452376.2452402},
	doi = {10.1145/2452376.2452402},
	abstract = {Good database design is typically a very difficult and costly process. As database systems get more complex and as the amount of data under management grows, the stakes increase accordingly. Past research produced a number of design tools capable of automatically selecting secondary indexes and materialized views for a known workload. However, a significant bulk of research on automated database design has been done in the context of row-store DBMSes. While this work has produced effective design tools, new specialized database architectures demand a rethinking of automated design algorithms. In this paper, we present results for an automatic design tool that is aimed at column-oriented DBMSes on OLAP workloads. In particular, we have chosen a commercial column store DBMS that supports data sorting. In this setting, the key problem is selecting proper sort orders and compression schemes for the columns as well as appropriate pre-join views. This paper describes our automatic design algorithms as well as the results of some experiments using it on realistic data sets.},
	urldate = {2022-05-27},
	booktitle = {Proceedings of the 16th {International} {Conference} on {Extending} {Database} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Rasin, Alexander and Zdonik, Stan},
	month = mar,
	year = {2013},
	pages = {203--214},
	file = {Volltext:/home/claudia/Zotero/storage/SBHJGXK6/Rasin und Zdonik - 2013 - An automatic physical design tool for clustered co.pdf:application/pdf},
}

@inproceedings{schnaitter_colt_2006,
	address = {New York, NY, USA},
	series = {{SIGMOD} '06},
	title = {{COLT}: continuous on-line tuning},
	isbn = {978-1-59593-434-5},
	shorttitle = {{COLT}},
	url = {https://doi.org/10.1145/1142473.1142592},
	doi = {10.1145/1142473.1142592},
	abstract = {The physical schema of a database plays a critical role in performance. Self-tuning is a cost-effective and elegant solution to optimize the physical configuration for the characteristics of the query load. Existing techniques operate in an off-line fashion, by choosing a fixed configuration that is tailored to a subset of the query load. The generated configurations therefore ignore any temporal patterns that may exist in the actual load submitted to the system.This demonstration introduces COLT (Continuous On-Line Tuning), a novel self-tuning framework that continuously monitors the incoming queries and adjusts the system configuration in order to maximize query performance. The key idea behind COLT is to gather performance statistics at different levels of detail and to carefully allocate profiling resources to the most promising candidate configurations. Moreover, COLT uses effective heuristics to regulate its own performance, lowering its overhead when the system is well-tuned, and being more aggressive when the workload shifts and it becomes necessary to re-tune the system. We present a specialization of COLT to the important problem of selecting an effective set of relational indices for the current query load. Our demonstration will use an implementation of our proposed framework in the PostgreSQL database system, showing the internal operation of COLT and the adaptive selection of indices as we vary the query load of the server.},
	urldate = {2022-05-27},
	booktitle = {Proceedings of the 2006 {ACM} {SIGMOD} international conference on {Management} of data},
	publisher = {Association for Computing Machinery},
	author = {Schnaitter, Karl and Abiteboul, Serge and Milo, Tova and Polyzotis, Neoklis},
	month = jun,
	year = {2006},
	keywords = {COLT, demonstration, index, on-line, selection, self-tuning},
	pages = {793--795},
	file = {Schnaitter et al. - 2006 - COLT continuous on-line tuning.pdf:/home/claudia/Zotero/storage/W7MGD66R/Schnaitter et al. - 2006 - COLT continuous on-line tuning.pdf:application/pdf},
}

@misc{noauthor_scope_nodate,
	title = {{SCOPE}: self-adaptive and policy-based data management middleware for federated clouds},
	shorttitle = {{SCOPE}},
	url = {https://www.springerprofessional.de/scope-self-adaptive-and-policy-based-data-management-middleware-/16432338},
	abstract = {A federated cloud storage setup which integrates and utilizes storage resources from multiple cloud storage providers has become an increasingly popular and attractive paradigm for the persistence tier in cloud-based applications (e.g., SaaS …},
	language = {de},
	urldate = {2022-05-27},
	journal = {springerprofessional.de},
	file = {SCOPE self-adaptive and policy-based data managem.pdf:/home/claudia/Zotero/storage/VTQS2KF5/SCOPE self-adaptive and policy-based data managem.pdf:application/pdf;Snapshot:/home/claudia/Zotero/storage/BCIX27KE/16432338.html:text/html},
}

@inproceedings{mior_nose_2016,
	address = {Helsinki, Finland},
	title = {{NoSE}: {Schema} design for {NoSQL} applications},
	isbn = {978-1-5090-2020-1},
	shorttitle = {{NoSE}},
	url = {http://ieeexplore.ieee.org/document/7498239/},
	doi = {10.1109/ICDE.2016.7498239},
	urldate = {2022-05-27},
	booktitle = {2016 {IEEE} 32nd {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Mior, Michael J. and Salem, Kenneth and Aboulnaga, Ashraf and Liu, Rui},
	month = may,
	year = {2016},
	pages = {181--192},
	file = {Mior et al. - 2016 - NoSE Schema design for NoSQL applications.pdf:/home/claudia/Zotero/storage/K9I9A7ES/Mior et al. - 2016 - NoSE Schema design for NoSQL applications.pdf:application/pdf},
}

@inproceedings{vajk_denormalizing_2013,
	title = {Denormalizing data into schema-free databases},
	doi = {10.1109/CogInfoCom.2013.6719198},
	abstract = {With the proliferation of cloud service providers, the use of non-relational (NoSQL) data stores is increasing. In contrast to standard relational database schema design, which has its strong mathematical background in relational algebra and set theory, development with NoSQL data stores is largely based on empirical best practices. Furthermore, the huge variety of NoSQL variants may require different design considerations. In this paper, an algorithm is introduced to automatically derive cost and performance optimal schema in column-oriented data stores based on predefined queries and an initial relational database schema. Algorithms are given to perform database denormalization, as well as to transform the original queries to meet the newly created schemas.},
	booktitle = {2013 {IEEE} 4th {International} {Conference} on {Cognitive} {Infocommunications} ({CogInfoCom})},
	author = {Vajk, Tamás and Fehér, Péter and Fekete, Krisztián and Charaf, Hassan},
	month = dec,
	year = {2013},
	keywords = {Indexes, Relational databases, Cloud computing, Load modeling, Navigation, Optimization},
	pages = {747--752},
	file = {IEEE Xplore Abstract Record:/home/claudia/Zotero/storage/35ED9BN8/6719198.html:text/html;Vajk et al. - 2013 - Denormalizing data into schema-free databases.pdf:/home/claudia/Zotero/storage/96W32UZ4/Vajk et al. - 2013 - Denormalizing data into schema-free databases.pdf:application/pdf},
}

@inproceedings{vajk_automatic_2013,
	title = {Automatic {NoSQL} {Schema} {Development}: {A} {Case} {Study}},
	shorttitle = {Automatic {NoSQL} {Schema} {Development}},
	doi = {10.2316/P.2013.795-044},
	abstract = {This paper introduces an automatic NoSQL schema optimization that uses a normalized data schema as starting point, and compiles the schema that can serve the queries with minimal cost at a certain query load. Cloud service providers offer a huge variety of schema-less NoSQL data storage solutions. The flexibility of these data stores offer greater freedom in structuring the data than relational databases. However, it would be desirable to make use of the strong mathematical background of relational data structures. In this paper, we introduce an automatic NoSQL schema optimization that uses a normalized data schema as starting point. We analyze the predefined set of queries, and compile the schema that can serve the queries with minimal cost at a certain query load. The introduced process is performed on a conceptual model of the database, and the queries are defined in Object Constraint Language to simplify the analysis. The optimization algorithm is introduced through a case study.},
	author = {Vajk, T. and Deák, László and Fekete, K. and Mezei, G.},
	year = {2013},
}

@inproceedings{bermbach_informed_2015,
	title = {Informed {Schema} {Design} for {Column} {Store}-{Based} {Database} {Services}},
	doi = {10.1109/SOCA.2015.29},
	abstract = {While database schema options in relational database management systems are few and have been studied for decades, little effort has so far been devoted to NoSQL column stores. Today, schema design for column stores is still based on the gut feeling of the application developer instead of being approached systematically. This is even more critical as "good" schemas in column stores do not only depend on the data model of the application but also on the queries on that data: Poor schema design will either lead to a situation where not all queries can be answered or where some queries will show really poor performance. In this paper, we propose a systematic and informed approach to database schema design in NoSQL column stores by means of automated schema generation and application-specific schema ranking.},
	booktitle = {2015 {IEEE} 8th {International} {Conference} on {Service}-{Oriented} {Computing} and {Applications} ({SOCA})},
	author = {Bermbach, David and Müller, Steffen and Eberhardt, Jacob and Tai, Stefan},
	month = oct,
	year = {2015},
	keywords = {Indexes, Column Stores, Cost function, Data structures, Electronic mail, NoSQL Systems, Schema Design, Systematics},
	pages = {163--172},
	file = {Bermbach et al. - 2015 - Informed Schema Design for Column Store-Based Data.pdf:/home/claudia/Zotero/storage/B9Q57Q43/Bermbach et al. - 2015 - Informed Schema Design for Column Store-Based Data.pdf:application/pdf;IEEE Xplore Abstract Record:/home/claudia/Zotero/storage/WEIXUMRT/7399106.html:text/html},
}

@inproceedings{de_lima_workload-driven_2015,
	address = {New York, NY, USA},
	series = {{iiWAS} '15},
	title = {A workload-driven logical design approach for {NoSQL} document databases},
	isbn = {978-1-4503-3491-4},
	url = {https://doi.org/10.1145/2837185.2837218},
	doi = {10.1145/2837185.2837218},
	abstract = {NoSQL databases are designed to manage large volumes of data. Although they do not require a default schema associated with the data, they are categorized by data models. Because of this, data organization in NoSQL databases needs significant design decisions because they affect quality requirements such as scalability, consistency and performance. In traditional database design, on the logical modeling phase, a conceptual schema is transformed into a schema with lower abstraction and suitable to the target database data model. In this context, the contribution of this paper is an approach for logical design of NoSQL document databases. Our approach consists in a process that converts a conceptual modeling into efficient logical representations for a NoSQL document database. Workload information is considered to determine an optimized logical schema, providing a better access performance for the application. We evaluate our approach through a case study in the e-commerce domain and demonstrate that the NoSQL logical structure generated by our approach reduces the amount of items accessed by the application queries.},
	urldate = {2022-05-27},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Information} {Integration} and {Web}-based {Applications} \& {Services}},
	publisher = {Association for Computing Machinery},
	author = {de Lima, Claudio and dos Santos Mello, Ronaldo},
	month = dec,
	year = {2015},
	keywords = {conceptual schema, logical design, NoSQL document, workload},
	pages = {1--10},
	file = {de Lima und dos Santos Mello - 2015 - A workload-driven logical design approach for NoSQ.pdf:/home/claudia/Zotero/storage/9EY62EFS/de Lima und dos Santos Mello - 2015 - A workload-driven logical design approach for NoSQ.pdf:application/pdf},
}

@article{yang_optimising_2017,
	title = {Optimising column family for {OLAP} queries in {HBase}},
	copyright = {Copyright © 2017 Inderscience Enterprises Ltd.},
	url = {https://www.inderscienceonline.com/doi/epdf/10.1504/IJBDI.2017.081195},
	abstract = {Apache HBase is a column-oriented NoSQL key-value store built on top of the Hadoop distributed file-system. Logically, columns in HBase are grouped into column families. Physically, all columns in one column family are stored in the same set of files. Therefore the division of column families is closely related to the response time for a specific row query. In this paper, a new evolutionary algorithm is designed and applied to group columns and find the optimum column family schema for the given user queries. The reading performance of the optimised column family schema is evaluated on a real dataset provided by ZANOX. It is shown that by using the found optimised column family schema, the reading performance while executing OLAP queries is improved with a statistical significance. Queries from a test set show that the average response time is reduced by up to 72\% compared to reference column family schemas.},
	language = {en},
	urldate = {2022-05-27},
	journal = {International Journal of Big Data Intelligence},
	author = {Yang, Fangzhou and Milosevic, Dragan and Cao, Jian},
	month = jan,
	year = {2017},
	note = {Publisher: Inderscience Publishers (IEL)},
	file = {Snapshot:/home/claudia/Zotero/storage/ZSWMV5XX/IJBDI.2017.html:text/html;Yang et al. - 2017 - Optimising column family for OLAP queries in HBase.pdf:/home/claudia/Zotero/storage/8VC68H6Z/Yang et al. - 2017 - Optimising column family for OLAP queries in HBase.pdf:application/pdf},
}

@inproceedings{saur_evolving_2016,
	title = {Evolving {NoSQL} {Databases} without {Downtime}},
	doi = {10.1109/ICSME.2016.47},
	abstract = {NoSQL databases like Redis, Cassandra, and Mon-goDB are increasingly popular because they are flexible, lightweight, and easy to work with. Applications that use these databases will evolve over time, sometimes necessitating (or preferring) a change to the format or organization of the data. The problem we address in this paper is: How can we support the evolution of high-availability applications and their NoSQL data online, without excessive delays or interruptions, even in the presence of backward-incompatible data format changes? We present KVolve, an extension to the popular Redis NoSQL database, as a solution to this problem. KVolve permits a developer to submit an upgrade specification that defines how to transform existing data to the newest version. This transformation is applied lazily as applications interact with the database, thus avoiding long pause times. We demonstrate that KVolve is expressive enough to support substantial practical updates, including format changes to RedisFS, a Redis-backed file system, while imposing essentially no overhead in general use and minimal pause times during updates.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Software} {Maintenance} and {Evolution} ({ICSME})},
	author = {Saur, Karla and Dumitraş, Tudor and Hicks, Michael},
	month = oct,
	year = {2016},
	keywords = {Relational databases, Arrays, Benchmark testing, Encoding, Servers, Software},
	pages = {166--176},
	file = {Eingereichte Version:/home/claudia/Zotero/storage/TLY2BUWM/Saur et al. - 2016 - Evolving NoSQL Databases without Downtime.pdf:application/pdf;IEEE Xplore Abstract Record:/home/claudia/Zotero/storage/MNSVK8SF/7816464.html:text/html},
}

@article{mozaffari_const_2021,
	title = {{CONST}: {Continuous} online {NoSQL} schema tuning},
	volume = {51},
	issn = {1097-024X},
	shorttitle = {{CONST}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2945},
	doi = {10.1002/spe.2945},
	abstract = {Self-tuning is a feature of autonomic databases that includes the problem of automatic schema design. Automating the schema design process is critical to provide an optimized schema that increases the performance of an application's workload in NoSQL databases. There has been important work on automated design tuning for NoSQL databases. Existing solutions take an offline approach to the schema design problem and leave several important decisions to database administrators. Although offline approaches recommend good and efficient schemas, their analysis is far too heavy-weight to be run continuously. This paper develops a novel self-tuning control loop, called CONST, for online monitoring, analysis, and schema tuning a managed NoSQL database system that automatically modify the current schema design reacting to changes in the application's workload. CONST provides components that fulfill IBM's MAPE-K loop phases to support self-tuning. We describe an implementation of the proposed CONST loop on top of the Cassandra wide column store and evaluate its performance experimentally. Our results show the low overhead of CONST and demonstrate its ability to tune a schema design in response to changes in the application's workload.},
	language = {en},
	number = {5},
	urldate = {2022-05-27},
	journal = {Software: Practice and Experience},
	author = {Mozaffari, Maryam and Nazemi, Eslam and Eftekhari-Moghadam, Amir-Masoud},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2945},
	keywords = {workload monitoring and analysis, automatic schema design tuning, autonomic databases, NoSQL wide column stores, workload change detection},
	pages = {1147--1169},
	file = {Mozaffari et al. - 2021 - CONST Continuous online NoSQL schema tuning.pdf:/home/claudia/Zotero/storage/WHTPM97Z/Mozaffari et al. - 2021 - CONST Continuous online NoSQL schema tuning.pdf:application/pdf;Snapshot:/home/claudia/Zotero/storage/4V269QVC/spe.html:text/html},
}

@article{preuveneers_automated_2020,
	title = {Automated {Configuration} of {NoSQL} {Performance} and {Scalability} {Tactics} for {Data}-{Intensive} {Applications}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-9709},
	url = {https://www.mdpi.com/2227-9709/7/3/29},
	doi = {10.3390/informatics7030029},
	abstract = {This paper presents the architecture, implementation and evaluation of a middleware support layer for NoSQL storage systems. Our middleware automatically selects performance and scalability tactics in terms of application specific workloads. Enterprises are turning to NoSQL storage technologies for their data-intensive computing and analytics applications. Comprehensive benchmarks of different Big Data platforms can help drive decisions which solutions to adopt. However, selecting the best performing technology, configuring the deployment for scalability and tuning parameters at runtime for an optimal service delivery remain challenging tasks, especially when application workloads evolve over time. Our middleware solves this problem at runtime by monitoring the data growth, changes in the read-write-query mix at run-time, as well as other system metrics that are indicative of sub-optimal performance. Our middleware employs supervised machine learning on historic and current monitoring information and corresponding configurations to select the best combinations of high-level tactics and adapt NoSQL systems to evolving workloads. This work has been driven by two real world case studies with different QoS requirements. The evaluation demonstrates that our middleware can adapt to unseen workloads of data-intensive applications, and automate the configuration of different families of NoSQL systems at runtime to optimize the performance and scalability of such applications.},
	language = {en},
	number = {3},
	urldate = {2022-07-26},
	journal = {Informatics},
	author = {Preuveneers, Davy and Joosen, Wouter},
	month = sep,
	year = {2020},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {hyperparameter tuning, machine learning, resource optimization, smart environments},
	pages = {29},
	file = {Preuveneers_Joosen_2020_Automated Configuration of NoSQL Performance and Scalability Tactics for.pdf:/home/claudia/Zotero/storage/MNMHWSXD/Preuveneers_Joosen_2020_Automated Configuration of NoSQL Performance and Scalability Tactics for.pdf:application/pdf;Snapshot:/home/claudia/Zotero/storage/L5NAU278/29.html:text/html},
}

@article{van_aken_inquiry_2021,
	title = {An inquiry into machine learning-based automatic configuration tuning services on real-world database management systems},
	volume = {14},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3450980.3450992},
	doi = {10.14778/3450980.3450992},
	abstract = {Modern database management systems (DBMS) expose dozens of configurable knobs that control their runtime behavior. Setting these knobs correctly for an application's workload can improve the performance and efficiency of the DBMS. But because of their complexity, tuning a DBMS often requires considerable effort from experienced database administrators (DBAs). Recent work on automated tuning methods using machine learning (ML) have shown to achieve better performance compared with expert DBAs. These ML-based methods, however, were evaluated on synthetic workloads with limited tuning opportunities, and thus it is unknown whether they provide the same benefit in a production environment. To better understand ML-based tuning, we conducted a thorough evaluation of ML-based DBMS knob tuning methods on an enterprise database application. We use the OtterTune tuning service to compare three state-of-the-art ML algorithms on an Oracle installation with a real workload trace. Our results with OtterTune show that these algorithms generate knob configurations that improve performance by 45\% over enterprise-grade configurations. We also identify deployment and measurement issues that were overlooked by previous research in automated DBMS tuning services.},
	number = {7},
	urldate = {2022-07-31},
	journal = {Proceedings of the VLDB Endowment},
	author = {Van Aken, Dana and Yang, Dongsheng and Brillard, Sebastien and Fiorino, Ari and Zhang, Bohan and Bilien, Christian and Pavlo, Andrew},
	month = mar,
	year = {2021},
	pages = {1241--1253},
	file = {Van Aken et al_2021_An inquiry into machine learning-based automatic configuration tuning services.pdf:/home/claudia/Zotero/storage/8FHRHGMU/Van Aken et al_2021_An inquiry into machine learning-based automatic configuration tuning services.pdf:application/pdf},
}

@article{chaudhuri_index_2004,
	title = {Index selection for databases: a hardness study and a principled heuristic solution},
	volume = {16},
	issn = {1558-2191},
	shorttitle = {Index selection for databases},
	doi = {10.1109/TKDE.2004.75},
	abstract = {We study the index selection problem: Given a workload consisting of SQL statements on a database, and a user-specified storage constraint, recommend a set of indexes that have the maximum benefit for the given workload. We present a formal statement for this problem and show that it is computationally "hard" to solve or even approximate it. We develop a new algorithm for the problem which is based on treating the problem as a knapsack problem. The novelty of our approach lies in an LP (linear programming) based method that assigns benefits to individual indexes. For a slightly modified algorithm, that does more work, we prove that we can give instance specific guarantees about the quality of our solution. We conduct an extensive experimental evaluation of this new heuristic and compare it with previous solutions. Our results demonstrate that our solution is more scalable while achieving comparable quality.},
	number = {11},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Chaudhuri, S. and Datar, M. and Narasayya, V.},
	month = nov,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Database systems, Indexes, Costs, approximation, Computer Society, Constraint optimization, hardness result, Index Terms- Index selection, knapsack, linear programming, Linear programming, NP-hardness, Paper technology, Scalability, scalability.},
	pages = {1313--1323},
	file = {Chaudhuri et al_2004_Index selection for databases.pdf:/home/claudia/Zotero/storage/IX53EFVA/Chaudhuri et al_2004_Index selection for databases.pdf:application/pdf;IEEE Xplore Abstract Record:/home/claudia/Zotero/storage/BYEJWQVG/1339260.html:text/html},
}

@book{noauthor_pioneers_2001,
	title = {Pioneers and {Their} {Contributions} to {Software} {Engineering} sd\&m {Conference} on {Software} {Pioneers}, {Bonn}, {June} 28/29, 2001, {Original} {Historic} {Contributions}},
	isbn = {978-3-642-48354-7},
	url = {https://doi.org/10.1007/978-3-642-48354-7},
	language = {German},
	urldate = {2022-07-31},
	year = {2001},
	note = {OCLC: 864024740},
	file = {2001_Pioneers and Their Contributions to Software Engineering sd&m Conference on.pdf:/home/claudia/Zotero/storage/SLEB8WZQ/2001_Pioneers and Their Contributions to Software Engineering sd&m Conference on.pdf:application/pdf},
}

@inproceedings{farias_machine_2016,
	address = {Cartagena, Colombia},
	title = {Machine {Learning} {Approach} for {Cloud} {NoSQL} {Databases} {Performance} {Modeling}},
	isbn = {978-1-5090-2453-7},
	url = {http://ieeexplore.ieee.org/document/7515747/},
	doi = {10.1109/CCGrid.2016.83},
	urldate = {2022-08-15},
	booktitle = {2016 16th {IEEE}/{ACM} {International} {Symposium} on {Cluster}, {Cloud} and {Grid} {Computing} ({CCGrid})},
	publisher = {IEEE},
	author = {Farias, Victor A. E. and Sousa, Flavio R. C. and Maia, Jose G. R. and Gomes, Joao P. P. and Machado, Javam C.},
	month = may,
	year = {2016},
	pages = {617--620},
	file = {Farias et al_2016_Machine Learning Approach for Cloud NoSQL Databases Performance Modeling.pdf:/home/claudia/Zotero/storage/LUHYMBX4/Farias et al_2016_Machine Learning Approach for Cloud NoSQL Databases Performance Modeling.pdf:application/pdf},
}

@article{chaudhuri_self-tuning_nodate,
	title = {Self-{Tuning} {Database} {Systems}: {A} {Decade} of {Progress}},
	abstract = {In this paper we discuss advances in self-tuning database systems over the past decade, based on our experience in the AutoAdmin project at Microsoft Research. This paper primarily focuses on the problem of automated physical database design. We also highlight other areas where research on self-tuning database technology has made significant progress. We conclude with our thoughts on opportunities and open issues.},
	language = {en},
	author = {Chaudhuri, Surajit and Narasayya, Vivek},
	pages = {12},
	file = {Chaudhuri und Narasayya - Self-Tuning Database Systems A Decade of Progress.pdf:/home/claudia/Zotero/storage/WLRPWBNI/Chaudhuri und Narasayya - Self-Tuning Database Systems A Decade of Progress.pdf:application/pdf},
}
